---
title: "iterSim"
output: html_document
params:
  epo: 2000
  patience: 5
  iteration: 10
  layer1: 12
  layer2: 12
  layer3: 100
  layer4: 100
  drpt: 0.1
  lr: 0.01
---

```{r}

library(reticulate)
```

```{python}

import os
os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID" 
os.environ["CUDA_VISIBLE_DEVICES"] = ""


```


```{r setup, include=T}
set.seed(1)
knitr::opts_chunk$set(echo = TRUE)
source("src/packages.R")
source("src/functions.R")
eval_support<-T
#source_python('src/getSUP.py')
source_python("src/cIndex.py")
#source_python("src/dsmScript.py")
#source_python('src/deephitter.py')
##########################
###Shared Hyperparameters
##########################
#bsize=512
min_delta = 0# 10^-7

epo=as.numeric(params$epo)
patience <- as.numeric(params$patience)
iteration<-as.numeric(params$iteration)

numSamp<-2000

baselineTrials<-5

reoptimize=T

finalFit=T
```


#5 fold cross validation to select best hyperparameters, average performance on a test set.

```{r supPrep,eval=T}

source_python('src/getSUP.py')
data<- as.data.frame(do.call(cbind, getSupportPycox()))

colnames(data)[ncol(data)-1]<-'time'
colnames(data)[ncol(data)]<-'status'


#for(i in c(2,5,6,7,16)){#3,4,
#  data[, i]<-as.factor(data[, i])
#}
data<-as.data.frame(model.matrix(~.,data)[,-1])
#data<-as.data.frame(sapply(data, function(x) (x - min(x, na.rm = T)) / (max(x, na.rm = T) - min(x, na.rm=T))))

covs<-colnames(data)
names(data)[ncol(data)-2] <- paste("z", ncol(data)-2, sep="")
names(data)[ncol(data)-1]<-"time"
names(data)[ncol(data)]<-"status"

covs<-colnames(data)
data<-data[,-1]

toDiv<-max(data$time)
data$time<-data$time/toDiv
#data$time<-data$time/max(data$time)
spec = c(train = .85, test = .15)

g = sample(cut(
  seq(nrow(data)), 
  nrow(data)*cumsum(c(0,spec)),
  labels = names(spec)
))

res = split(data, g)
saveRDS(res$test,"supportTest.rds")


k=5
klist<-list()
data<-res$train
for(i in 1:k){
  
  
  
  spec = c(train = .85, val = .15)
  
  g = sample(cut(
    seq(nrow(data)), 
    nrow(data)*cumsum(c(0,spec)),
    labels = names(spec)
  ))
  klist[[i]]= split(data, g)
}
saveRDS(klist,"supportCV.rds")




```

```{r setFixedHyperparameters}


klist<-readRDS("supportCV.rds")


lr=c(0.001,0.0001)
drpt=c(.1,.2)
layer1=c(10,25,50)
layer2=c(10,20,30)
bsize=c(floor(nrow(klist[[1]]$train)/100))
actv=c("relu","tanh")
alp=c(0,0.5,1)





```

```{r hyperOpDsurv,eval=reoptimize}




optimDeepSurv<-function(klist,test,times,baselineTrials,lr,drpt,layer1,layer2,bsize,actv){
  
  paramTrials<-as.data.frame(tidyr::crossing(lr=lr,
                                             drpt=drpt,
                                             layer1=layer1,
                                             layer2=layer2,
                                             bsize=c(bsize),
                                             actv=actv,
                                             #IPA=NA,
                                             #IPAse=NA,
                                             valLoss=NA,
                                             runtime=NA))
  
  #paramTrials<-paramTrials[sample(nrow(paramTrials), 2), ]
  
  
  
  
  
  
  # paramTrials<-unique.data.frame(paramTrials)
  #paramTrials<-readRDS("complexTrials.rds")
  for(i in 1:nrow(paramTrials)){
    #paramTrials<-readRDS("complexTrials.rds")  
    tempRes<-c()
    tempVal<-c()
    runTime<-c()
    
    for(data in klist){
      
      train<-data$train
      val<-data$val
      
      sds<-sapply(train, function(x) (sd(x)))
      means<-sapply(train, function(x) (mean(x)))
      val<-normalizer(val,means,sds)
      train<-normalizer(train,means,sds)
      
      lr=paramTrials[i,]$lr
      drpt=paramTrials[i,]$drpt
      layer1=paramTrials[i,]$layer1
      layer2=paramTrials[i,]$layer2
      bsize=paramTrials[i,]$bsize
      actv=paramTrials[i,]$actv
      #=paramTrials[i,]$IPA
      #=paramTrials[i,]$valLoss
      source_python('src/optimDSurv.py')
      
      
      currentTime<-Sys.time() 
      coxnnsurv=fitDeepSurv(train,val,floor(nrow(train)/100),epochs=epo,valida=val,patience=patience,min_delta=min_delta,drpt=drpt,lay1=layer1,lay2=layer2,lr=lr,actv=actv)
      tempVal<-append(tempVal,min(coxnnsurv$val_metrics$scores$loss$score))
      runTime<-append(runTime, Sys.time()-currentTime)
      currentTime<-Sys.time() 
      
      # coxnnsurv<-coxnnsurv[[1]]
      # coxnnsurv<-t(coxnnsurv)
      # #colnames(coxnnsurv)<-seq(0,1,length.out = ncol(coxnnsurv))
      # cnnCleaned<-pyProcess(coxnnsurv,times=times)
      # colnames(cnnCleaned)<-times#seq(0,1,length.out = ncol(cnnCleaned))
      # py_run_string("del fitDeepSurv")
      rm(fitDeepSurv)
      # brierFinalResults <- Score(list('ds'=cnnCleaned),
      #                            data =as.data.frame(val),#rbind(train,val) 
      #                            formula = Hist(time, status != 0) ~ 1, summary = c("risks","IPA","ibs"), 
      #                            se.fit = FALSE, metrics = "brier", contrasts = FALSE, times = times)$Brier$score
      # cutted<-brierFinalResults[which(brierFinalResults$model=="ds"),]
      #tempRes<-append(tempRes,mean(cutted[-c(1,2,24,25)]$IPA))
    }
    
    #paramTrials$IPA[i]<-mean(tempRes)
    #paramTrials$IPAse[i]<-sd(tempRes)
    paramTrials$valLoss[i]<-mean(tempVal)
    paramTrials$runtime[i]<-mean(runTime)
    #saveRDS(paramTrials,"complexds.rds")
    print(paste("trial",i))
    print(sum(runTime))
    #print(as.character(paramTrials[i,]))
    #rm(cbnn,fit,annPreds,covars_input,covars_output)
    gc()
  }
  bestPerformance<-paramTrials[which.min(paramTrials$valLoss),]
  return(bestPerformance)
}



klist<-readRDS("supportCV.rds")
test<-readRDS("supportTest.rds")
  times<-seq(from=min(test$time)+0.000001,
             to=max(test$time)-0.000001,
             length.out = 25
  )

bestDS<-optimDeepSurv(klist,test,times,baselineTrials=baselineTrials,lr,drpt,layer1,layer2,bsize,actv)

```

```{r optimDeepHit,eval=reoptimize}



optimDeepHit<-function(klist,test,times,baselineTrials,lr,drpt,layer1,layer2,bsize,actv,alp){
  
  paramTrials<-as.data.frame(tidyr::crossing(lr=lr,
                                             drpt=drpt,
                                             layer1=layer1,
                                             layer2=layer2,
                                             bsize=c(bsize),
                                             actv=actv,
                                             alp=alp,
                                             #IPA=NA,
                                             #IPAse=NA,
                                             valLoss=NA,
                                             runtime=NA))
  
  #paramTrials<-paramTrials[sample(nrow(paramTrials), 2), ]
  
  
  
  
  
  
  # paramTrials<-unique.data.frame(paramTrials)
  #paramTrials<-readRDS("complexTrials.rds")
  for(i in 1:nrow(paramTrials)){
    #paramTrials<-readRDS("complexTrials.rds")  
    tempRes<-c()
    tempVal<-c()
    runTime<-c()
    
    for(data in klist){
      
      train<-data$train
      val<-data$val
      
      sds<-sapply(train, function(x) (sd(x)))
      means<-sapply(train, function(x) (mean(x)))
      val<-normalizer(val,means,sds)
      train<-normalizer(train,means,sds)
      
      lr=paramTrials[i,]$lr
      drpt=paramTrials[i,]$drpt
      layer1=paramTrials[i,]$layer1
      layer2=paramTrials[i,]$layer2
      bsize=paramTrials[i,]$bsize
      actv=paramTrials[i,]$actv
      alp=paramTrials[i,]$alp
      #=paramTrials[i,]$IPA
      #=paramTrials[i,]$valLoss
      source_python('src/optimDH.py')
      
      
      currentTime<-Sys.time() 
      hitnnSurv=fitDeephit(train,val,floor(nrow(train)/100),
                           epochs=epo,valida=val,patience=patience,
                           min_delta=min_delta,drpt=drpt,
                           lay1=layer1,lay2=layer2,
                           lr=lr,actv=actv,alp=alp
                           )

      tempVal<-append(tempVal,min(hitnnSurv$val_metrics$scores$loss$score))
      runTime<-append(runTime, Sys.time()-currentTime)
      currentTime<-Sys.time() 
    }
    rm(fitDeephit)
    
    #paramTrials$IPA[i]<-mean(tempRes)
    #paramTrials$IPAse[i]<-sd(tempRes)
    paramTrials$valLoss[i]<-mean(tempVal)
    paramTrials$runtime[i]<-mean(runTime)
    #saveRDS(paramTrials,"complexds.rds")
    print(paste("trial",i))
    print(mean(runTime))
    #print(as.character(paramTrials[i,]))
    #rm(cbnn,fit,annPreds,covars_input,covars_output)
    gc()
  }
  bestPerformance<-paramTrials[which.min(paramTrials$valLoss),]
  return(bestPerformance)
}



klist<-readRDS("supportCV.rds")
test<-readRDS("supportTest.rds")
  times<-seq(from=min(test$time)+0.000001,
             to=max(test$time)-0.000001,
             length.out = 25
  )

bestDH<-optimDeepHit(klist,test,times,baselineTrials=baselineTrials,lr,drpt,layer1,layer2,bsize,actv,alp)




```


```{r hyperopcbnn,eval=reoptimize}




optimCBNN<-function(klist,test,times,lr,drpt,layer1,layer2,bsize,actv){
  

    # for (i in 1:length(klist)){
  #   train<-sampleCaseBase(data = as.data.frame(klist[[i]]$train),time="time",event="status",ratio=100)
  #   valcb<-sampleCaseBase(data = as.data.frame(klist[[i]]$val),time="time",event="status",ratio=100)
  #   valcbtensor<-list(list(as.matrix(valcb[,-c(ncol(valcb)-1,ncol(valcb))]),
  #                          as.matrix(valcb[,ncol(valcb),drop=F])),
  #                     as.matrix(valcb[,ncol(valcb)-1,drop=F]))
  #   valcbtensor[[1]][[2]]<-rep(train$offset[1],nrow(valcbtensor[[1]][[1]]))      
  #   klist[[i]]$train<-train
  #   klist[[i]]$val<-valcbtensor
  # }
  
  
  

  
  
  paramTrials<-as.data.frame(tidyr::crossing(lr=lr,
                                             drpt=drpt,
                                             layer1=layer1,
                                             layer2=layer2,
                                             actv=actv,
                                             #IPA=NA,
                                             #IPAse=NA,
                                             valLoss=NA,
                                             runtime=NA))
  
  # paramTrials<-unique.data.frame(paramTrials)
  #paramTrials<-readRDS("complexTrials.rds")
  for(i in 1:nrow(paramTrials)){
    #paramTrials<-readRDS("complexTrials.rds")  
    tempRes<-c()
    tempVal<-c()
    runTime<-c()
    
    for(data in klist){
      
      
      
      
      train<-data$train
      val<-data$val
      
      sds<-sapply(train, function(x) (sd(x)))
      means<-sapply(train, function(x) (mean(x)))
      #val[[1]][[1]]<-as.matrix(normalizer(as.data.frame(val[[1]][[1]]),means,sds))
      train<-normalizer(train,means,sds)
     # train[,ncol(train)]<-data$train[,ncol(train)]
      val<-normalizer(val,means,sds)
      train<-sampleCaseBase(data = as.data.frame(train),time="time",event="status",ratio=100)
      valcb<-sampleCaseBase(data = as.data.frame(val),time="time",event="status",ratio=100)
      val<-list(list(as.matrix(valcb[,-c(ncol(valcb)-1,ncol(valcb))]),
                     as.matrix(valcb[,ncol(valcb),drop=F])),
                as.matrix(valcb[,ncol(valcb)-1,drop=F]))
      
      val[[1]][[2]]<-rep(train$offset[1],nrow(val[[1]][[1]]))   
      
      
      
      
      lr=paramTrials[i,]$lr
      drpt=paramTrials[i,]$drpt
      layer1=paramTrials[i,]$layer1
      layer2=paramTrials[i,]$layer2
      bsize=c(floor(nrow(train)/100))
      actv=paramTrials[i,]$actv
      
      
      
      currentTime<-Sys.time() 
      
      covars_input<-layer_input(shape=c(length(colnames(train))-2),
                                name = 'main_input')
      
      covars_output<-covars_input%>%
        layer_dense(units=layer1,use_bias = T,activation = actv)%>%
        layer_dropout(drpt)%>%
        layer_dense(units=layer2,use_bias = T,activation = actv)%>%
        layer_dropout(drpt)%>%
        layer_dense(units=1,use_bias = T)
      
      cbnn<-cbnnModel(features=colnames(train)[-ncol(train)],
                      feature_input = covars_input,
                      feature_output = covars_output,
                      originalData = train,
                      offset=train$offset,
                      timeVar = "time",
                      eventVar= "status",optimizer=optimizer_adam(learning_rate = lr)
      )
      
      fit<-fitSmoothHaz(cbnn,
                        epochs=epo,
                        batch_size=bsize,
                        verbose=0,
                        monitor="val_loss",
                        #val_split=0.2,
                        min_delta=min_delta,
                        patience=patience,val=val)
      tempVal<-append(tempVal,min(fit$resultOfFit$metrics$val_loss))
      runTime<-append(runTime, Sys.time()-currentTime)
      currentTime<-Sys.time() 
      
      rm(cbnn,fit,covars_input,covars_output)
    }
    paramTrials$valLoss[i]<-mean(tempVal)
    paramTrials$runtime[i]<-mean(runTime)
    #saveRDS(paramTrials,"complexds.rds")
    print(paste("trial",i,"out of ",nrow(paramTrials)))
    print(sum(runTime))
    #print(as.character(paramTrials[i,]))
    #rm(cbnn,fit,annPreds,covars_input,covars_output)
    gc()
  }
  bestPerformance<-paramTrials[which.min(paramTrials$valLoss),]
  return(bestPerformance)
}


klist<-readRDS("supportCV.rds")
test<-readRDS("supportTest.rds")

cbnnPerformance<-optimCBNN(klist,test,times,lr,drpt,layer1,layer2,bsize,actv)
#cbnnPerformance<-cbnnPerformance[which.min(cbnnPerformance$valLoss),]
winners<-list(cbnn=cbnnPerformance,
              ds=bestDS,
              dh=bestDH)

saveRDS(winners,"supportWins.rds")

```

```{r bestFits,finalFit}

winners<-readRDS("supportWins.rds")


klist<-readRDS("supportCV.rds")
data<-rbind(klist[[1]]$train,klist[[1]]$val)
#data$time<-data$time/max(data$time)




start_time <- Sys.time()
BrierIPAList<-list()
cScore<-list()
pos<-1


spec = c(train = .85, validate = .15)

g = sample(cut(
  seq(nrow(data)), 
  nrow(data)*cumsum(c(0,spec)),
  labels = names(spec)
))

res = split(data, g)


while (pos <= iteration) {
  
  
  
  
  
  trainOG<-res$train
  
  numSamp<-nrow(trainOG)
  samp<-sample(seq(1,nrow(trainOG),by=1) , nrow(trainOG),replace = T) 
  train<-trainOG[samp,]
  
  val<-res$validate
  
  sds<-sapply(train, function(x) (sd(x)))
  means<-sapply(train, function(x) (mean(x)))
  
  fullTest<-readRDS("supportTest.rds")
  test<-fullTest[,-c(ncol(data))]
  test<-normalizer(fullTest,means,sds)[,-c(ncol(data))]
  fullTest<-normalizer(fullTest,means,sds)
  
  val<-normalizer(res$validate,means,sds)
  
  train<-normalizer(train,means,sds)

  
  times<-seq(from=min(test$time)+0.000001,
             to=max(test$time)-0.000001,
             length.out = 27
  )
  
  times<-head(times, -1)
  times<-tail(times, -1)
  
  
  
  
  #########################
  ###casebase+splines
  ##########################
  mod_cb_glm <- fitSmoothHazard(status~bs(time)+.-time,
                                data = train,
                                time = "time",
                                event="status",
                                ratio = 100
  )
  
  glmAbsRisk<-as.data.frame(absoluteRisk(mod_cb_glm,time=times,newdata=test,type="CI"))
  rownames(glmAbsRisk)<-glmAbsRisk$time
  glmProper<- t(glmAbsRisk[-1,-1])
  class(glmProper)<-c("tunnel",class(glmProper))
  
  
  
  #############################
  ###DEEPSURV
  #############################
  
  lr=0.001#winners$ds$lr
  drpt=winners$ds$drpt
  layer1=winners$ds$layer1
  layer2=winners$ds$layer2
  bsize=winners$ds$bsize
  actv=winners$ds$actv
  source_python('src/dsurv.py')
  coxnnsurv=fitDeepSurv(train,fullTest,bsize,epochs=epo,valida=val,patience=patience,min_delta=min_delta,drpt=drpt,lay1=layer1,lay2=layer2,lr=lr,actv=actv)
  coxnnsurv<-t(coxnnsurv)
  cnnCleaned<-pyProcess(coxnnsurv,times=times)
  colnames(cnnCleaned)<-times
  py_run_string("del fitDeepSurv")
  rm(fitDeepSurv)
  
  #############################
  ###DEEPHIT
  #############################
  lr=winners$dh$lr
  drpt=winners$dh$drpt
  layer1=winners$dh$layer1
  layer2=winners$dh$layer2
  bsize=winners$dh$bsize
  actv=winners$dh$actv
  alp=winners$dh$alp
  source_python('src/deephitter.py')
  hitnnSurv=fitDeephit(train,fullTest,floor(nrow(train)/100),epochs=epo,valida=val,patience=patience,min_delta=min_delta,drpt=drpt,lay1=layer1,lay2=layer2,lr=lr,actv=actv,alp=alp)
  hitnnSurv<-t(hitnnSurv)
  deephitCleaned<-pyProcess(hitnnSurv,times=times)
  colnames(deephitCleaned)<-times
  py_run_string("del fitDeephit")
  rm(fitDeephit)
  
  
  
  ############################
  ###coxph
  ############################  
  cox<-coxph(Surv(time, status) ~ ., data = train,x=T)
  
  
  #############################
  ###CBNN
  #############################
          train<-sampleCaseBase(data = as.data.frame(train),time="time",event="status",ratio=100)
      valcb<-sampleCaseBase(data = as.data.frame(val),time="time",event="status",ratio=100)
      val<-list(list(as.matrix(valcb[,-c(ncol(valcb)-1,ncol(valcb))]),
                     as.matrix(valcb[,ncol(valcb),drop=F])),
                as.matrix(valcb[,ncol(valcb)-1,drop=F]))
      
      val[[1]][[2]]<-rep(train$offset[1],nrow(val[[1]][[1]]))   
  lr=winners$cbnn$lr
  drpt=winners$cbnn$drpt
  layer1=winners$cbnn$layer1
  layer2=winners$cbnn$layer2
  #bsize=winners$cbnn$bsize
  actv=winners$cbnn$actv
  
  # lr=0.001
  # drpt=0.1
  # layer1=50
  # layer2=20
  # #bsize=winners$cbnn$bsize
  # actv='relu'


      
  currentTime<-Sys.time() 
  #valcbtensor[[1]][[2]]<-rep(mod_cb_glm$offset[1],nrow(valcbtensor[[1]][[1]]))
  
  covars_input<-layer_input(shape=c(length(colnames(mod_cb_glm$data))-2),
                            name = 'main_input')
  
  covars_output<-covars_input%>%
    layer_dense(units=layer1,use_bias = T,activation = actv)%>%
    layer_dropout(drpt)%>%
    layer_dense(units=layer2,use_bias = T,activation = actv)%>%
    layer_dropout(drpt)%>%
    layer_dense(units=1,use_bias = T)
  
      cbnn<-cbnnModel(features=colnames(train)[-ncol(train)],
                      feature_input = covars_input,
                      feature_output = covars_output,
                      originalData = train,
                      offset=train$offset,
                      timeVar = "time",
                      eventVar= "status",optimizer=optimizer_adam(learning_rate = lr)
      )

        fit<-fitSmoothHaz(cbnn,
                        epochs=epo,
                        batch_size=c(floor(nrow(train)/100)),
                        verbose=0,
                        monitor="val_loss",
                        #val_split=0.2,
                        min_delta=min_delta,
                        patience=patience,val=val)
  annPreds<-aar(fit,
                times=times,
                x_test=test
  )
  
  rownames(annPreds)<-annPreds[,1]
  annProperpoly<- t(annPreds[,-1])
  class(annProperpoly)<-c("tunnel",class(annProperpoly)) 
  rm(fit,cbnn,covars_input,covars_output)
  ############################
  ###Brier Score
  ############################  
  brierFinalResults <- Score(list("Cox_Lin" = cox,'CB_Logi'=glmProper,
                                  'DeepSurv'=cnnCleaned,'DeepHit'=deephitCleaned,
                                  'CBNN_Poly'=annProperpoly),
                             data =fullTest, 
                             formula = Hist(time, status != 0) ~ 1, summary = c("risks","IPA","ibs"), 
                             se.fit = FALSE, metrics = "brier", contrasts = FALSE, times = times)
  BrierIPAList[[pos]]<-brierFinalResults$Brier$score
  
    ggplot(data=brierFinalResults$Brier$score, aes(x=times,y=IPA,col=model))+
  geom_line()#+coord_cartesian(ylim=c(-0.1,0.2))
  #######################
  ###Cox 
  ######################
  a<-survfit(cox, newdata=fullTest,times=times)
  rownames(a$surv)<-a$time
  coxlinSurv<-pyProcess(t(a$surv),times=times)
  colnames(coxlinSurv)<-seq(0,1,length.out = ncol(coxlinSurv))
  
  
  ######################
  ###C-Index
  ######################
  
  riskList<-list(coxlinSurv,
                 glmProper,
                 cnnCleaned,
                 deephitCleaned,
                 annProperpoly
  )
  
  
  tempTims<-   as.numeric(colnames(annProperpoly))
  tempTims<-head(tempTims, -1)
  tempTims<-tail(tempTims, -1)
  cScoreTemp<-matrix(NA,nrow=length(tempTims),ncol=length(riskList)+1)
  et_train<-as.matrix(train)[,c(ncol(train),ncol(train)-1)]
  et_test<-as.matrix(fullTest[,c(ncol(train),ncol(train)-1)])
  colnames(cScoreTemp)<-c('times', "Cox_Lin",'CB_Logi','DeepSurv','DeepHit',
                          'cbnn')
  cScoreTemp[,1]<- tempTims
  
  cScore[[pos]]<-cIndexSummary(et_train=et_train,
                               et_test=et_test,
                               riskList=riskList,
                               cScore=cScoreTemp
  )
  print(paste("current iter:",pos))
  saveRDS(BrierIPAList,'results/100supportBrier.rds')
  saveRDS(cScore,'results/100supportcidx.rds')
  pos=pos+1
  
}


```




```{r plotsupport}



BrierIPAList<-readRDS('results/100supportBrier.rds')

ipaSims=data.frame(model=BrierIPAList[[1]]$model,times=BrierIPAList[[1]]$times)
brierSims=data.frame(model=BrierIPAList[[1]]$model,times=BrierIPAList[[1]]$times)
ibsSims=data.frame(model=BrierIPAList[[1]]$model,times=BrierIPAList[[1]]$times)
ibsTable<-as.data.frame(matrix(data=NA,nrow=100,ncol=length(unique(BrierIPAList[[1]]$model))))
colnames(ibsTable)<-unique(BrierIPAList[[1]]$model)
count=1
for(sim in BrierIPAList){
  ipaSims<-cbind(ipaSims, sim$IPA)
  brierSims<-cbind(brierSims,sim$Brier)
  ibsSims<-cbind(ibsSims,sim$IBS)
  for(mod in colnames(ibsTable)){
    
    ibsTable[count,which(mod ==colnames(ibsTable))]<-sim$IBS[sim$model==mod & sim$time==max(sim$time)]
    
  }
  count<-count+1
}
ibsTable<-na.omit(ibsTable)
ibsOverall<-data.frame(mean=apply(ibsTable,2,mean),sd = apply(ibsTable,2,sd))
ibsOverall
ipaSummary<-statCalcSim(ipaSims)
brierSummary<-statCalcSim(brierSims)
ibsSummary<-statCalcSim(ibsSims)
ipa<-plotPerformance(ipaSummary,method="IPA",iterations=iteration  )
brier<-plotPerformance(brierSummary,method="BS",iterations=iteration )
ibs<-plotPerformance(ibsSummary,method="IBS",iterations=iteration )

ipa+coord_cartesian(ylim=c(-0.1,0.2))
#end_time-start_time



```
